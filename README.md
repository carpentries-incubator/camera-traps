# Camera-Trap-Workshop

## Overview of the Camera Trap Wrangling workshop

Data Carpentry's aim is to teach researchers basic concepts, skills, and tools for working with data so that they can get more done in less time, and with less pain. This workshop uses an raw camera trap dataset and teaches data cleaning, management, analysis and visualization. There are no pre-requisites, and the materials assume no prior knowledge about the tools.

The workshop uses a single camera trap data set that contains observations about snow leopards (Panthera uncia) in the Wakhan Corridor of Afghanistan. See `data.md` for more information about this data set, including the download location.

Overview of the lessons:

  1. Data organization using camTrapR
  * Camera Trap Data in R 
  * Introduction to Python Megadetector (species identification)
  * Introduction to Whiskerbook (individual identification)
  * Data wrangling in R 
  * oSCR for spatial-capture recapture

## Detailed structure

### Day 1 morning: Data organization & cleaning

There are two lessons in this section. The first is a camera trap lesson that teaches  good data organization, and some data cleaning and quality control checking in a camera trap program.

  * [camTrapR lesson](http://###)
  * [camTrapR repository](http://###)

The second lesson uses a program called [Megadetector]() to teach species identification, and to introduce scripting and regular expressions.

  * [Megadetector lesson](http://###)
  * [Megadetector repository](http://###)

### Day 1 afternoon and Day 2 morning: Whiskerbook 

These lessons includes a basic introduction the Whiskerbook platform, importing CSV data, using the main features of the programs. 

  * [Whiskerbook lesson](http://###) 
  * [Whiskerbook repository](http://###) 


### Day 2 afternoon: Data Wrangling and oSCR

These lessons includes a basic introduction to R syntax for wrangling data for input into the oSCR program. Topics include importing CSV data, and subsetting and merging data. It finishes with calculating summary statistics and running the models. 

  * [SQL lesson](http://datacarpentry.org/sql-ecology-lesson/)
  * [SQL repository](https://github.com/datacarpentry/sql-ecology-lesson)

